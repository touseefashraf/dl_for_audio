{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a simple NN using TensorFlow \n",
    "Steps to follow:\n",
    "1.Build modal\n",
    "2.Compile modal\n",
    "3.Train modal\n",
    "4.Evaluate modal\n",
    "5.Train modal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 2)\n",
      "(2000, 1)\n"
     ]
    }
   ],
   "source": [
    "# created a data set of random numbers 2 columns of 2000 numbers \n",
    "x=np.array([[ random()/2 for _ in range(2)] for _ in range(2000)])\n",
    "# added the 2 number in a row save its result as y output \n",
    "# y= np.array([[i[0] + i[1]] for i in x])\n",
    "y= np.sum(x,axis=1).reshape(2000,1)\n",
    "print(np.shape(x))\n",
    "print(np.shape(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we want to split our data to training and test data set \n",
    "x_train, x_test,y_train,y_test=train_test_split(x,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can make function of it \n",
    "def dataset_generator(num_samples,test_size):\n",
    "    x=np.array([[ random()/2 for _ in range(2)] for _ in range(num_samples)])\n",
    "    # added the 2 number in a row save its result as y output \n",
    "    # y= np.array([[i[0] + i[1]] for i in x])\n",
    "    y= np.sum(x,axis=1).reshape(num_samples,1)\n",
    "    x_train, x_test,y_train,y_test=train_test_split(x,y,test_size=test_size)\n",
    "    return x_train, x_test,y_train,y_test\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "438/438 [==============================] - 2s 3ms/step - loss: 0.0209\n",
      "Epoch 2/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 1.1508e-04\n",
      "Epoch 3/100\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 1.0836e-05\n",
      "Epoch 4/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 5.5339e-06\n",
      "Epoch 5/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 3.3894e-06\n",
      "Epoch 6/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 2.3171e-06\n",
      "Epoch 7/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 1.6972e-06\n",
      "Epoch 8/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 1.3016e-06\n",
      "Epoch 9/100\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 1.0327e-06\n",
      "Epoch 10/100\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 8.4051e-07\n",
      "Epoch 11/100\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 6.9769e-07\n",
      "Epoch 12/100\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 5.8776e-07\n",
      "Epoch 13/100\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 5.0048e-07\n",
      "Epoch 14/100\n",
      "438/438 [==============================] - 2s 4ms/step - loss: 4.3009e-07\n",
      "Epoch 15/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 3.7290e-07\n",
      "Epoch 16/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 3.2526e-07\n",
      "Epoch 17/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 2.8544e-07\n",
      "Epoch 18/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 2.5190e-07\n",
      "Epoch 19/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 2.2425e-07\n",
      "Epoch 20/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 2.0051e-07\n",
      "Epoch 21/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 1.8024e-07\n",
      "Epoch 22/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 1.6268e-07\n",
      "Epoch 23/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 1.4762e-07\n",
      "Epoch 24/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 1.3438e-07\n",
      "Epoch 25/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 1.2284e-07\n",
      "Epoch 26/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 1.1263e-07\n",
      "Epoch 27/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 1.0341e-07\n",
      "Epoch 28/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 9.5587e-08\n",
      "Epoch 29/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 8.8355e-08\n",
      "Epoch 30/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 8.2043e-08\n",
      "Epoch 31/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 7.6354e-08\n",
      "Epoch 32/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 7.1321e-08\n",
      "Epoch 33/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 6.6808e-08\n",
      "Epoch 34/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 6.2771e-08\n",
      "Epoch 35/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 5.9125e-08\n",
      "Epoch 36/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 5.5871e-08\n",
      "Epoch 37/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 5.2953e-08\n",
      "Epoch 38/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 5.0307e-08\n",
      "Epoch 39/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 4.7922e-08\n",
      "Epoch 40/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 4.5735e-08\n",
      "Epoch 41/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 4.3697e-08\n",
      "Epoch 42/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 4.1878e-08\n",
      "Epoch 43/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 4.0152e-08\n",
      "Epoch 44/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 3.8559e-08\n",
      "Epoch 45/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 3.7026e-08\n",
      "Epoch 46/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 3.5630e-08\n",
      "Epoch 47/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 3.4322e-08\n",
      "Epoch 48/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 3.3007e-08\n",
      "Epoch 49/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 3.1826e-08\n",
      "Epoch 50/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 3.0732e-08\n",
      "Epoch 51/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 2.9683e-08\n",
      "Epoch 52/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 2.8666e-08\n",
      "Epoch 53/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 2.7705e-08\n",
      "Epoch 54/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 2.6809e-08\n",
      "Epoch 55/100\n",
      "438/438 [==============================] - 2s 4ms/step - loss: 2.5948e-08\n",
      "Epoch 56/100\n",
      "438/438 [==============================] - 2s 3ms/step - loss: 2.5091e-08\n",
      "Epoch 57/100\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 2.4312e-08\n",
      "Epoch 58/100\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 2.3498e-08\n",
      "Epoch 59/100\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 2.2777e-08\n",
      "Epoch 60/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 2.2069e-08\n",
      "Epoch 61/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 2.1388e-08\n",
      "Epoch 62/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 2.0735e-08\n",
      "Epoch 63/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 2.0122e-08\n",
      "Epoch 64/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 1.9522e-08\n",
      "Epoch 65/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 1.8934e-08\n",
      "Epoch 66/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 1.8399e-08\n",
      "Epoch 67/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 1.7879e-08\n",
      "Epoch 68/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 1.7366e-08\n",
      "Epoch 69/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 1.6896e-08\n",
      "Epoch 70/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 1.6438e-08\n",
      "Epoch 71/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 1.5990e-08\n",
      "Epoch 72/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 1.5555e-08\n",
      "Epoch 73/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 1.5160e-08\n",
      "Epoch 74/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 1.4768e-08\n",
      "Epoch 75/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 1.4392e-08\n",
      "Epoch 76/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 1.4015e-08\n",
      "Epoch 77/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 1.3689e-08\n",
      "Epoch 78/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 1.3341e-08\n",
      "Epoch 79/100\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 1.3023e-08\n",
      "Epoch 80/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 1.2719e-08\n",
      "Epoch 81/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 1.2421e-08\n",
      "Epoch 82/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 1.2146e-08\n",
      "Epoch 83/100\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 1.1926e-08\n",
      "Epoch 84/100\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 1.1614e-08\n",
      "Epoch 85/100\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 1.1352e-08\n",
      "Epoch 86/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 1.1128e-08\n",
      "Epoch 87/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 1.0881e-08\n",
      "Epoch 88/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 1.0671e-08\n",
      "Epoch 89/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 1.0451e-08\n",
      "Epoch 90/100\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 1.0243e-08\n",
      "Epoch 91/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 1.0041e-08\n",
      "Epoch 92/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 9.8421e-09\n",
      "Epoch 93/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 9.6576e-09\n",
      "Epoch 94/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 9.4729e-09\n",
      "Epoch 95/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 9.2960e-09\n",
      "Epoch 96/100\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 9.1247e-09\n",
      "Epoch 97/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 8.9607e-09\n",
      "Epoch 98/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 8.7990e-09\n",
      "Epoch 99/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 8.6446e-09\n",
      "Epoch 100/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 8.4938e-09\n"
     ]
    }
   ],
   "source": [
    "# calling the dataset function \n",
    "if __name__ == \"__main__\":\n",
    "    x_train, x_test,y_train,y_test=dataset_generator(5000,0.3)\n",
    "    # print(f'tarining set x{x_train}')\n",
    "    # print(f'tarining set y{y_train}')\n",
    "    # print(f'test set x{x_test}')\n",
    "    # print(f'test set y{y_test}')\n",
    "    \n",
    "    # building the modal using TF \n",
    "    modal=tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(5,input_dim=2,activation=\"relu\"), #using relu is gives better results than sigmoid\n",
    "        tf.keras.layers.Dense(1,activation=\"relu\") #using relu is gives better results than sigmoid\n",
    "        \n",
    "    ])\n",
    "    # compile the modal \n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "    modal.compile(optimizer=optimizer,loss=\"MSE\")\n",
    "    \n",
    "    # training the modal \n",
    "    modal.fit(x_train,y_train,epochs=100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 0s 2ms/step - loss: 1.6764e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.676354521862322e-08"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now evaluating the modal \n",
    "modal.evaluate(x_test,y_test,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 78ms/step\n",
      "0.5+0.3=0.800000011920929\n",
      "0.4+0.8=1.1200000047683716\n"
     ]
    }
   ],
   "source": [
    "# Now make prediction using our modal \n",
    "data=np.array([[0.5,0.3],[0.4,0.8]])\n",
    "predict=modal.predict(data)\n",
    "\n",
    "for d,p in zip(data,predict):\n",
    "\n",
    "    print(f'{d[0]}+{d[1]}={np.round(p[0],2)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "872297596d866abac5f8ee2e50e2eeb543af31a9f9c1bd6008203e0c51f332d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
